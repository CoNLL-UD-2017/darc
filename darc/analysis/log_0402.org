experiment results on grc-proiel

* first model

0 form upos feat
1 emb emb
2 inputs
3 hidden
4 output

hidden-units=200 upos-emb-dim=10

** old setup (unnormalized deprel)

| sgd         | adagrad     | adadelta    | rmsprop     | adam        | adamax      | nadam       |
|-------------+-------------+-------------+-------------+-------------+-------------+-------------|
| 62.78 55.42 | 72.66 68.41 | 72.70 68.09 | 73.78 69.28 | 75.53 71.23 | 74.45 70.19 | 74.99 70.47 |
| 67.89 61.95 | 75.10 71.02 | 74.76 70.58 | 75.78 71.54 | 77.13 73.02 | 76.60 72.26 | 74.41 69.70 |
| 71.21 65.81 | 75.52 71.42 | 75.92 72.00 | 75.75 71.48 | 76.53 72.53 | 76.86 72.52 | 73.93 69.09 |
| 72.17 67.48 | 75.64 71.58 | 76.55 72.56 | 76.07 71.75 | 76.61 72.59 | 77.67 73.63 | 74.26 69.84 |
| 72.05 67.40 | 75.91 71.95 | 77.17 73.12 | 76.64 72.25 | 76.11 71.89 | 77.81 73.63 | 75.03 70.17 |
| 74.09 69.66 | 76.22 72.25 | 76.60 72.71 | 76.33 71.86 | 75.83 71.54 | 77.55 73.48 | 74.51 69.59 |
| 74.27 70.00 | 76.57 72.55 | 77.12 73.05 | 75.25 71.16 | 75.78 71.19 | 76.69 72.70 | 73.92 68.95 |
| 74.70 70.31 | 76.56 72.58 | 77.30 73.15 | 74.57 70.19 | 74.89 70.34 | 77.19 72.89 | 73.53 68.37 |
| 75.88 71.32 | 77.04 72.92 | 77.53 73.65 | 74.49 70.25 | 74.60 69.94 | 77.11 73.04 | 73.13 68.28 |
| 76.10 71.76 | 76.93 72.93 | 76.71 72.91 | 74.95 70.57 | 74.81 70.29 | 77.07 72.77 | 74.25 69.23 |

** new setup

| adadelta    | adam        | adamax      |
|-------------+-------------+-------------|
| 71.95 67.43 | 75.22 71.23 | 74.30 70.17 |
| 74.16 69.98 | 77.72 73.49 | 76.94 72.78 |
| 76.27 72.24 | 77.20 73.32 | 78.24 73.86 |
| 77.00 73.03 | 76.51 72.32 | 77.55 73.56 |
| 76.61 72.60 | 75.42 71.23 | 78.12 73.98 |
| 76.56 72.76 | 75.65 71.69 | 78.14 74.07 |
| 77.66 73.66 | 74.63 70.30 | 76.98 72.73 |
| 77.87 73.92 | 74.00 69.56 | 77.79 73.45 |
| 76.63 72.63 | 74.64 70.28 | 78.19 74.08 |
| 76.93 73.04 | 75.12 70.30 | 77.07 72.70 |

** conclusion

adamax

* optimize hidden-units

optimizer=adamax upos-emb-dim=10

** old setup (unnormalized deprel)

| 50          | 100         | 150         | 200         | 250         | 300         |
|-------------+-------------+-------------+-------------+-------------+-------------|
| 72.84 68.14 | 73.99 69.35 | 74.38 70.06 | 74.70 70.14 | 74.13 69.71 | 75.18 71.04 |
| 74.86 70.52 | 75.24 71.14 | 76.50 72.18 | 75.93 71.57 | 76.40 72.08 | 76.55 72.38 |
| 74.96 70.74 | 76.38 72.39 | 76.76 72.80 | 77.74 73.39 | 76.66 72.66 | 77.94 73.96 |
| 76.28 71.78 | 76.47 72.33 | 77.51 73.42 | 78.54 74.09 | 78.15 73.73 | 76.57 72.44 |
| 76.82 72.43 | 76.88 72.55 | 78.63 74.33 | 77.98 73.80 | 77.69 73.56 | 77.95 73.78 |
| 76.88 72.52 | 76.25 72.16 | 77.89 73.61 | 78.06 73.85 | 77.83 73.46 | 77.55 73.23 |
| 76.05 71.87 | 76.54 72.53 | 77.84 73.70 | 77.94 73.70 | 77.17 72.93 | 77.31 73.29 |
| 76.27 72.00 | 77.12 72.88 | 76.89 72.49 | 78.30 74.04 | 77.67 73.59 | 78.04 73.89 |
| 75.99 71.65 | 76.21 71.93 | 77.40 73.05 | 77.57 73.24 | 77.22 73.07 | 77.63 73.56 |
| 76.00 71.76 | 76.22 71.97 | 76.35 72.10 | 77.83 73.56 | 77.56 73.28 | 77.14 72.91 |

** conclusion

200

* try normalized feat

since feat is a multi-hot vector, normalize by l2 make it unit, normalize by l1
make it a probability distribution; maybe always fill dim 0 as the dummy, to deal
with null vectors

optimizer=adamax hidden-units=200 upos-emb-dim=10

** old setup (unnormalized deprel)

| l1 no dummy | l1 dummy    | l2 no dummy | l2 dummy    |
|-------------+-------------+-------------+-------------|
| 72.27 67.37 | 72.22 66.94 | 73.62 69.18 | 73.10 68.34 |
| 74.55 69.79 | 74.74 70.21 | 75.78 71.56 | 75.18 70.93 |
| 75.48 70.99 | 76.30 71.59 | 77.51 73.36 | 75.98 71.95 |
| 76.10 71.73 | 76.13 72.03 | 77.11 72.85 | 76.73 72.55 |
| 76.46 72.08 | 76.05 71.77 | 77.23 72.99 | 76.76 72.70 |
| 75.79 71.66 | 76.11 71.90 | 76.92 72.48 | 77.54 73.29 |
| 76.20 71.74 | 76.22 71.70 | 76.61 72.53 | 76.06 72.00 |
| 76.63 72.09 | 76.29 71.97 | 76.41 72.26 | 77.31 73.23 |
| 76.10 71.39 | 76.12 71.89 | 76.25 72.13 | 76.79 72.66 |
| 76.13 71.54 | 76.04 71.59 | 76.08 71.68 | 76.10 71.83 |

** conclusion

bad

* try feat-emb

take the average of feat present in feats

optimizer=adamax hidden-units=200 upos-emb-dim=10

** old setup (unnormalized deprel)

feat-emb-dim=

| 25          | 50          | 75          |
|-------------+-------------+-------------|
| 71.29 65.50 | 72.00 66.85 | 73.13 67.95 |
| 75.26 70.06 | 75.27 70.55 | 76.28 71.93 |
| 75.32 70.87 | 76.34 72.25 | 76.67 72.01 |
| 76.65 72.17 | 77.39 73.06 | 77.19 72.95 |
| 76.65 72.26 | 76.47 72.37 | 77.25 73.05 |
| 76.90 72.63 | 77.37 73.25 | 77.04 72.74 |
| 76.19 71.96 | 76.98 72.69 | 77.12 72.82 |
| 76.68 72.07 | 76.89 72.69 | 76.69 72.39 |
| 76.66 72.41 | 76.78 72.54 | 77.31 72.89 |
| 75.42 71.18 | 76.79 72.49 | 77.21 73.10 |

** conclusion

bad

* try l2 regularization

hidden-units=200 upos-emb-dim=10

hidden-l2=.001

| adam        | adamax      |
|-------------+-------------|
| 70.64 65.48 | 70.23 65.48 |
| 71.55 66.77 | 71.29 66.80 |
| 73.05 68.16 | 72.88 68.14 |
| 73.53 68.66 | 73.49 68.68 |
| 72.86 68.55 | 74.85 70.01 |
| 72.93 67.79 | 73.29 68.80 |
| 73.01 68.35 | 74.96 70.26 |
| 73.34 68.46 | 74.44 70.24 |
| 72.42 67.95 | 75.96 71.40 |
| 73.00 68.40 | 74.68 70.40 |

hidden-l2=.001 output-l2=.001

| adam        | adamax      |
|-------------+-------------|
| 68.47 62.57 | 68.63 63.10 |
| 69.13 64.25 | 69.27 64.44 |
| 72.09 67.10 | 71.67 66.44 |
| 71.63 66.91 | 72.41 67.46 |
| 72.62 67.73 | 73.66 68.46 |
| 72.93 67.53 | 73.00 68.01 |
| 70.69 65.57 | 73.27 68.30 |
| 71.51 66.27 | 72.17 67.38 |
| 70.71 66.17 | 74.24 69.13 |
| 70.39 65.63 | 74.10 69.33 |


hidden-l2=.001 output-l2=.001 emb-l2=.001

| adam        | adamax      |
|-------------+-------------|
| 67.69 62.08 | 68.43 63.18 |
| 68.68 62.72 | 68.13 62.47 |
| 66.60 60.75 | 69.84 64.53 |
| 68.02 62.58 | 70.30 64.53 |
| 69.80 64.09 | 68.30 62.55 |
| 68.38 62.24 | 70.05 64.61 |
| 70.31 64.67 | 69.88 64.31 |
| 69.56 64.23 | 69.31 63.97 |
| 71.29 65.67 | 70.79 65.42 |
| 70.19 64.70 | 70.55 64.95 |

** conclusion

bad

* optimize upos-emb-dim

|upos| = 14 + 2

optimizer=adamax hidden-units=200

** old setup (unnormalized deprel)

| 5           | 10          | 15          | 20          |
|-------------+-------------+-------------+-------------|
| 73.83 69.58 | 74.11 69.91 | 74.79 70.51 | 74.84 70.38 |
| 76.19 72.08 | 76.11 71.93 | 76.81 72.66 | 76.16 72.08 |
| 76.76 72.37 | 77.40 73.07 | 76.74 72.44 | 77.78 73.56 |
| 77.49 73.18 | 77.02 72.95 | 78.06 74.00 | 76.65 72.49 |
| 77.09 73.03 | 77.54 73.48 | 77.47 73.54 | 77.25 73.12 |
| 77.40 73.15 | 78.05 73.86 | 77.10 73.12 | 77.12 73.30 |
| 78.00 73.75 | 77.75 73.59 | 77.04 73.00 | 78.07 73.86 |
| 77.15 72.91 | 76.93 72.75 | 76.98 72.83 | 77.67 73.53 |
| 77.25 72.80 | 77.72 73.55 | 77.38 73.28 | 76.40 72.16 |
| 77.49 73.32 | 77.16 72.96 | 77.21 72.99 | 77.83 73.57 |

** new setup

| 10          | 15          |
|-------------+-------------|
| 74.30 70.17 | 74.30 70.00 |
| 76.94 72.78 | 77.29 73.42 |
| 78.24 73.86 | 77.91 73.62 |
| 77.55 73.56 | 77.48 73.43 |
| 78.12 73.98 | 77.92 73.96 |
| 78.14 74.07 | 77.65 73.64 |
| 76.98 72.73 | 77.63 73.25 |
| 77.79 73.45 | 76.88 72.86 |
| 78.19 74.08 | 77.86 73.68 |
| 77.07 72.70 | 77.18 72.79 |

** conclusion

10

* try 1hot upos

hidden-units=200

| adadelta    | adamax      |
|-------------+-------------|
| 71.76 67.34 | 73.55 69.29 |
| 74.78 70.64 | 76.69 72.32 |
| 74.85 70.83 | 77.40 73.66 |
| 76.00 72.02 | 77.47 73.60 |
| 77.08 73.02 | 77.37 73.43 |
| 76.94 73.07 | 76.96 72.89 |
| 77.29 73.39 | 77.11 73.03 |
| 77.62 73.55 | 76.52 72.77 |
| ----- ----- | 76.89 72.74 |
| ----- ----- | 76.37 72.35 |

** conclusion

bad

* try l1 reg on upos-emb

optimizer=adamax hidden-units=200 upos-emb-dim=30

l1=

| 0.01        | 0.001       |
|-------------+-------------|
| 72.55 68.47 | 73.88 69.84 |
| 75.53 71.36 | 76.77 72.80 |
| 75.95 71.67 | 77.81 73.83 |
| 77.18 73.24 | 77.78 73.50 |
| 75.92 71.61 | 78.09 74.14 |
| 76.59 72.46 | 77.43 73.12 |
| 76.67 72.76 | 77.32 73.04 |
| 76.99 72.67 | 77.16 72.82 |
| 76.36 72.17 | 77.10 73.06 |
| 76.47 72.27 | 77.01 72.73 |

** conclusion

bad

* try valency feature

optimizer=adamax hidden-units=200 upos-emb-dim=10

for children of s0&s1, add multi-hot

| deprel      | upos        |
|-------------+-------------|
| 75.96 71.78 | 75.26 70.85 |
| 77.75 73.44 | 76.35 72.36 |
| 77.57 73.56 | 76.95 72.90 |
| 78.24 74.30 | 77.53 73.54 |
| 77.31 73.39 | 77.67 73.91 |
| 77.57 73.71 | 77.23 73.29 |
| 78.34 74.58 | 76.79 72.77 |
| 78.12 74.18 | 77.12 73.03 |
| 76.84 72.88 | 77.31 73.21 |
| ----- ----- | 76.71 72.47 |

** conclusion

could be helpful for labeled parsing

* try norm constraint

optimizer=adamax hidden-units=200 upos-emb-dim=10

on form-emb

| unit axis=1 | unit axis=0 | max 1 0     | max 2 0     |
|-------------+-------------+-------------+-------------|
| 74.86 70.83 | 75.49 71.10 | 75.02 70.81 | 73.52 69.29 |
| 77.80 73.75 | 76.82 72.82 | 77.86 73.70 | 77.21 73.39 |
| 76.97 73.18 | 78.27 74.47 | 77.37 73.51 | 78.00 74.23 |
| 77.83 73.98 | 78.00 74.33 | 78.54 74.63 | 77.97 74.11 |
| 78.44 74.54 | 79.39 75.77 | 79.39 75.42 | 79.45 75.67 |
| 77.97 74.21 | 78.46 74.59 | 78.36 74.60 | 79.30 75.47 |
| 77.45 73.59 | 79.39 75.45 | 79.36 75.59 | 78.66 75.05 |
| 77.64 73.86 | 78.89 74.94 | 78.27 74.57 | 79.48 75.79 |
| 77.23 73.45 | 79.32 75.56 | 78.95 75.15 | 78.53 75.02 |
| 77.48 73.69 | 78.78 75.01 | 78.68 74.96 | 78.45 74.79 |

axis=0

on form-emb & upos-emb

| unit        | max 1       |
|-------------+-------------|
| 74.76 70.57 | 74.67 70.52 |
| 76.38 72.25 | 76.49 72.42 |
| 76.83 73.02 | 77.74 73.95 |
| 78.74 74.99 | 77.57 73.89 |
| 79.18 75.29 | 78.51 74.74 |
| 78.95 75.30 | 78.68 75.00 |
| 78.92 75.09 | 79.12 75.28 |
| 79.69 75.96 | 78.44 74.84 |
| 79.00 74.99 | 78.95 75.07 |
| 79.73 75.93 | 78.12 74.42 |

unit-norm on form-emb & upos-emb
on hidden

| unit        | max 1       | max 2       |
|-------------+-------------+-------------|
| 70.38 65.81 | 70.27 65.32 | 72.79 68.50 |
| 70.89 65.74 | 72.05 67.15 | 74.30 70.03 |
| 70.99 66.11 | 70.29 65.21 | 73.70 69.42 |
| 70.00 65.35 | 69.77 65.29 | 73.92 69.46 |
| 70.71 66.25 | 71.25 66.49 | 72.87 68.63 |
| 71.40 66.49 | 70.93 66.57 | 73.75 69.48 |
| 71.15 66.66 | 71.07 66.17 | 74.47 70.25 |
| 71.17 66.35 | 68.95 64.43 | 75.03 70.43 |
| 70.88 65.98 | 71.04 66.20 | 74.87 70.70 |
| 69.89 65.07 | 70.75 66.16 | 74.47 70.35 |

unit-norm on form-emb & upos-emb & feat-emb(dim=30)

** conclusion

unit-norm on form-emb & upos-emb

* optimize upos-emb-dim with unit-norm

|upos| = 14 + 2

optimizer=adamax hidden-units=200
unit-norm on form-emb & upos-emb

| 5           | 10          | 15          | 20          |
|-------------+-------------+-------------+-------------|
| 74.90 70.68 | 74.76 70.57 | 74.74 70.66 | 74.77 70.71 |
| 76.33 72.40 | 76.38 72.25 | 76.34 72.49 | 77.14 73.25 |
| 77.75 73.86 | 76.83 73.02 | 76.79 73.10 | 78.49 74.57 |
| 77.83 74.03 | 78.74 74.99 | 78.14 74.44 | 79.02 74.96 |
| 77.19 73.60 | 79.18 75.29 | 78.60 74.60 | 78.43 74.63 |
| 78.06 74.24 | 78.95 75.30 | 79.08 75.37 | 78.75 74.82 |
| 78.24 74.68 | 78.92 75.09 | 78.85 75.17 | 79.02 75.18 |
| 78.29 74.41 | 79.69 75.96 | 79.50 75.74 | 79.34 75.59 |
| 78.19 74.61 | 79.00 74.99 | 79.15 75.29 | 78.70 74.77 |
| 79.54 75.74 | 79.73 75.93 | 78.14 74.52 | 79.46 75.81 |

** conclusion

stick with 10

* optimize optimizer with unit-norm

| adagrad     | adadelta    | adam        | nadam        | adamax      |
|-------------+-------------+-------------+--------------+-------------|
| 126m44.836s | 175m50.332s | 148m29.348s | 193m59.956s  | 140m29.928s |
| 328m25.384s | 460m2.180s  | 728m7.392s  | 1009m16.632s | 2565m5.508s |
|-------------+-------------+-------------+--------------+-------------|
| 71.54 67.14 | 72.95 68.58 | 74.83 69.82 | 72.80 68.00  | 74.63 70.39 |
| 73.38 69.21 | 73.55 69.36 | 77.09 72.69 | 74.69 70.03  | 77.15 73.19 |
| 74.86 70.66 | 75.74 71.73 | 76.08 71.60 | 74.98 70.36  | 76.81 72.96 |
| 74.57 70.50 | 76.90 72.86 | 77.32 73.10 | 77.17 72.35  | 78.17 74.22 |
| 74.63 70.59 | 77.20 73.55 | 77.45 73.29 | 76.26 71.41  | 78.78 74.92 |
| 75.30 71.36 | 76.99 73.03 | 77.70 73.24 | 75.44 70.50  | 79.39 75.31 |
| 75.29 71.39 | 77.71 73.99 | 77.37 73.04 | 75.56 70.76  | 78.86 74.99 |
| 75.07 71.15 | 77.26 73.33 | 77.36 73.07 | 76.62 71.62  | 79.59 75.77 |
| 75.21 71.37 | 78.22 74.36 | 76.47 72.29 | 75.02 70.09  | 79.29 75.46 |
| 75.62 71.74 | 78.22 74.31 | 77.26 72.52 | 76.41 71.42  | 79.23 75.16 |

** conclusion

stick with adamax

* try feat without the dummy node

| with dummy  | no dummy    |
|-------------+-------------|
| 74.37 70.46 | 74.71 70.46 |
| 77.64 73.48 | 77.44 73.51 |
| 78.35 74.32 | 77.77 73.72 |
| 77.82 73.81 | 78.63 74.61 |
| 79.41 75.58 | 79.09 75.14 |
| 79.34 75.58 | 78.74 74.87 |
| 78.93 75.19 | 78.99 75.05 |
| 78.42 74.36 | 78.67 74.95 |
| 78.66 74.84 | 78.38 74.55 |
| 79.40 75.58 | 78.98 75.04 |

** conclusion

why is the dummy helping ????

* try unlabeled models

hidden-units=

|    50 |   100 |   150 |   200 |
|-------+-------+-------+-------|
| 74.24 | 74.25 | 72.40 | 73.83 |
| 75.88 | 77.30 | 76.77 | 77.10 |
| 77.23 | 77.75 | 77.91 | 77.41 |
| 77.42 | 77.83 | 78.19 | 78.58 |
| 77.74 | 78.11 | 78.32 | 77.56 |
| 77.83 | 78.16 | 78.43 | 77.90 |
| 78.09 | 78.74 | 78.15 | 78.48 |
| 78.50 | 79.00 | 78.00 | 78.38 |
| 77.54 | 78.87 | 79.23 | 77.55 |
| 77.97 | 78.22 | 77.77 | 78.08 |

** conclusion

doing unlabeled parsing is not easier

* try valency feature again

| binary rel  | freq rel    |
|-------------+-------------|
| 75.04 70.89 | 75.16 70.72 |
| 76.72 72.82 | 75.85 72.07 |
| 78.09 74.22 | 77.72 73.57 |
| 78.12 74.18 | 78.22 74.48 |
| 78.41 74.74 | 78.79 74.83 |
| 78.88 75.16 | 78.93 75.06 |
| 78.17 74.38 | 77.83 74.07 |
| 78.33 74.35 | 79.55 75.75 |
| 79.17 75.25 | 79.13 75.34 |
| 78.54 74.64 | 78.44 74.69 |

** conclusion

not helping

* try dropout

on hidden 0.5
hidden-units=

| 200         | 300         | 400         | 512         |
|-------------+-------------+-------------+-------------|
| 71.84 67.35 | 71.55 67.15 | 73.12 69.01 | 72.28 67.60 |
| 73.18 68.88 | 73.88 69.70 | 74.53 70.43 | 74.88 70.88 |
| 73.87 69.88 | 74.59 70.80 | 74.71 70.56 | 74.68 70.60 |
| 74.74 70.55 | 74.63 70.49 | 74.71 70.94 | 74.62 70.66 |
| 74.49 70.66 | 75.22 71.25 | 74.69 70.91 | 75.43 71.55 |
| 75.31 71.66 | 75.73 71.91 | 75.10 71.23 | 76.66 72.82 |
| 75.24 71.46 | 75.77 71.85 | 75.19 71.28 | 76.41 72.66 |
| 74.36 70.70 | 75.84 72.05 | 76.22 72.41 | 76.59 72.94 |
| 75.38 71.60 | 75.77 72.11 | 76.53 72.71 | 76.90 73.05 |
| 75.21 71.43 | 76.12 72.35 | 76.85 73.01 | 77.29 73.51 |
| 76.09 72.44 | 76.38 72.74 | 76.74 72.85 | 77.25 73.44 |
| 75.75 72.12 | 76.59 72.91 | 77.15 73.29 | 76.26 72.54 |
| 75.67 72.09 | 76.37 72.64 | 76.25 72.52 | 77.41 73.75 |
| 76.16 72.63 | 76.44 72.64 | 77.18 73.48 | 77.51 73.95 |
| 76.31 72.64 | 75.98 72.38 | 77.39 73.62 | 77.37 73.71 |
| 76.10 72.60 | 75.84 72.14 | 77.79 73.93 | 77.31 73.52 |
| 75.56 71.91 | 76.74 72.93 | 77.59 73.77 | 77.48 73.81 |
| 76.36 72.76 | 76.68 72.91 | 77.18 73.59 | 78.22 74.52 |
| 76.74 72.83 | 77.24 73.49 | 77.33 73.52 | 77.83 74.18 |
| 77.12 73.56 | 76.68 73.21 | 77.53 73.89 | 77.92 74.24 |
| 76.74 73.19 | 77.42 73.84 | 77.55 73.95 | 78.06 74.27 |
| 76.77 73.10 | 76.35 72.87 | 77.40 73.78 | 78.14 74.54 |
| 76.46 72.94 | 77.28 73.79 | 76.72 73.14 | 78.31 74.68 |
| 76.61 72.90 | 76.87 73.30 | 77.52 73.96 | 78.16 74.48 |
| 75.97 72.50 | 76.77 73.16 | 77.04 73.43 | 78.35 74.77 |

on hidden 0.2
hidden-units=

| 200         | 250         | 300         |
|-------------+-------------+-------------|
| 73.64 69.37 | 73.47 69.37 | 74.19 69.98 |
| 76.18 71.95 | 75.83 71.86 | 75.61 71.46 |
| 76.34 72.46 | 76.38 72.46 | 76.35 72.26 |
| 77.20 73.30 | 76.03 72.14 | 77.55 73.54 |
| 77.84 73.92 | 76.04 72.38 | 77.70 73.79 |
| 77.76 73.80 | 77.33 73.28 | 77.65 73.85 |
| 78.29 74.34 | 78.20 74.49 | 78.42 74.35 |
| 78.11 74.33 | 78.83 75.07 | 79.08 75.42 |
| 78.41 74.81 | 78.52 74.82 | 78.34 74.86 |
| 78.24 74.39 | 78.39 74.79 | 78.60 74.86 |
| 77.80 74.11 | 78.33 74.64 | 79.07 75.48 |
| 78.49 74.76 | 78.56 74.60 | 78.98 75.34 |
| 77.78 74.16 | 79.35 75.58 | 79.08 75.70 |
| 78.33 75.00 | 79.06 75.32 | 78.87 75.12 |
| 78.20 74.59 | 79.32 75.65 | 78.82 75.14 |
| 78.57 74.89 | 78.69 75.04 | 79.21 75.50 |
| 78.24 74.53 | 78.49 74.77 | 79.34 75.89 |
| 79.01 75.15 | 78.93 75.27 | 79.48 75.75 |
| 78.34 74.46 | 79.27 75.42 | 78.85 75.20 |
| 79.51 75.72 | 78.49 74.83 | 78.46 74.83 |

on inputs

| 0.25        | 0.5         |
|-------------+-------------|
| 73.61 69.34 | 70.82 65.82 |
| 76.45 72.04 | 72.36 67.84 |
| 77.04 72.96 | 74.86 70.40 |
| 77.56 73.42 | 75.64 71.38 |
| 77.00 73.01 | 75.91 71.70 |
| 78.55 74.77 | 75.81 71.53 |
| 78.90 75.06 | 76.03 71.87 |
| 79.42 75.73 | 76.78 72.57 |
| 78.73 74.90 | 77.40 73.34 |
| 78.77 75.18 | 77.09 73.04 |

** conclusion

promising. better than regularization. more testing needed.

* try on farsi

optimizer

| sgd         | adagrad     | adadelta    | rmsprop     | adam        | adamax      | nadam       |
|-------------+-------------+-------------+-------------+-------------+-------------+-------------|
| 160m22.396s | 190m34.064s | 266m37.340s | 214m39.668s | 317m44.008s | 239m20.672s | 319m8.648s  |
| 46m8.972s   | 71m2.944s   | 89m59.664s  | 68m51.140s  | 94m39.984s  | 89m8.052s   | 96m7.268s   |
|-------------+-------------+-------------+-------------+-------------+-------------+-------------|
| 61.05 54.36 | 76.39 71.99 | 76.11 70.74 | 78.61 74.21 | 76.81 72.44 | 78.92 74.13 | 74.97 70.03 |
| 70.00 63.65 | 79.02 75.04 | 79.57 74.91 | 79.30 74.98 | 79.05 74.73 | 80.60 76.57 | 78.24 73.59 |
| 70.33 64.38 | 80.05 76.05 | 79.94 75.49 | 81.34 77.13 | 80.97 76.69 | 80.44 76.72 | 79.81 74.91 |
| 72.83 67.16 | 80.30 76.38 | 80.14 75.71 | 80.46 76.26 | 79.00 74.65 | 81.69 77.98 | 79.86 75.06 |
| 75.18 69.27 | 80.22 76.28 | 80.61 76.65 | 81.46 76.88 | 81.37 76.81 | 82.16 78.23 | 78.43 73.62 |
| 76.31 70.63 | 80.56 76.88 | 81.73 77.70 | 81.01 76.73 | 80.19 75.93 | 82.58 78.75 | 80.15 75.37 |
| 77.29 71.60 | 80.79 77.02 | 81.87 77.96 | 80.96 76.79 | 81.28 76.83 | 82.66 78.51 | 78.73 74.24 |
| 77.96 72.61 | 80.34 76.68 | 82.43 78.58 | 81.32 77.07 | 81.41 77.41 | 82.96 78.95 | 78.79 74.00 |
| 77.61 72.44 | 81.03 77.22 | 82.52 78.63 | 81.37 77.43 | 81.55 77.49 | 81.54 77.82 | 79.99 75.33 |
| 78.80 73.54 | 80.64 76.78 | 82.14 78.33 | 81.48 77.06 | 80.54 76.33 | 81.95 77.97 | 78.71 74.12 |

constraint

| none        | unit        | max 1       | max 2       |
|-------------+-------------+-------------+-------------|
| 78.23 73.92 | 78.92 74.13 | 79.67 75.17 | 76.38 72.20 |
| 81.16 77.05 | 80.60 76.57 | 80.59 76.69 | 80.85 76.90 |
| 81.32 77.22 | 80.44 76.72 | 81.03 76.99 | 81.18 77.35 |
| 81.82 78.05 | 81.69 77.98 | 81.71 77.89 | 81.51 77.94 |
| 82.54 78.73 | 82.16 78.23 | 82.84 78.99 | 83.10 79.46 |
| 81.50 77.44 | 82.58 78.75 | 82.24 78.25 | 82.14 78.42 |
| 82.45 78.52 | 82.66 78.51 | 82.67 79.01 | 82.39 78.58 |
| 82.18 78.43 | 82.96 78.95 | 82.61 78.77 | 82.80 78.77 |
| 80.29 76.26 | 81.54 77.82 | 81.94 77.97 | 82.24 78.46 |
| 81.51 77.56 | 81.95 77.97 | 81.94 78.03 | 81.97 78.08 |

proj

| 77.91 73.42 |
| 81.33 77.39 |
| 81.02 76.72 |
| 80.57 76.31 |
| 82.76 78.86 |
| 80.84 76.94 |
| 81.39 77.57 |
| 81.97 78.20 |
| 81.56 77.45 |
| 82.84 79.06 |

** conclusion

stick with adamax

unit-norm is stabler than max-norm, but max-norm seems to have better
potential. try max-norm again after dropout.

projective parsing seems to be alright with farsi's non-projectivity:
train:6.86%, dev:4.84%.
