for [[http://universaldependencies.org/conll17/][the conll 2017 shared task]]

* deps

  - python3
  - numpy
  - Keras
  - tensorflow
  - gensim

* train

** train tokenizers and taggers with [[https://github.com/ufal/udpipe][udpipe]]

   and run on the gold standard =train= to produce =silver-train=:

   we used the =(detokenized-)baselinemodel-splits=, but took both =train= and
   =tune= for =train=, and =dev= for =tune=. and we used the same parameters as
   the baseline models.

** train embeddings with [[https://github.com/wlin12/wang2vec][wang2vec]]

   on =silver-train=:

   =-type 3 -hs 0 -min-count 2 -window 7 -sample 0.1 -negative 7 -iter 20=

*** 64 dim form embeddings for

    =ug= =en_lines= =sv_lines= =id= =pt_br= =ko=

*** 32 dim form embeddings & 32 dim lemma embeddings for

    the rest

** train darc models

   on =silver-train=

* parse

** tokenize and tag raw texts with udpipe models

   for surprise languages, take the conllu input provided by the shared task.

** parse with darc models

   for surprise languages, pick the closest model.
